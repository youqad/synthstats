# SubTB hyperparameter sweep configuration
# Usage: python scripts/train_skyrl.py --multirun hydra/launcher=arc \
#        trainer.learning_rate=1e-5,5e-5,1e-4 trainer.logZ_lr=0.01,0.1

defaults:
  - override /hydra/launcher: arc
  - override /hydra/sweeper: basic

hydra:
  sweep:
    dir: /data/coml-prog-synthesis/${oc.env:USER}/sweeps/${now:%Y-%m-%d_%H-%M-%S}
    subdir: ${hydra.job.num}

# Default sweep parameters (override via CLI)
# Example: --multirun trainer.learning_rate=1e-5,5e-5,1e-4
